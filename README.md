# CS320


Project Reflection

	Software development is a wonderful resource for companies. We create things for clients that allows their businesses to be more productive and make more money. We can even help them avoid unnecessary expenditures like overheard costs and physical shop location expenses. We created this app and thoroughly tested it for the client. The team all helped each other with the workload, and we were able to efficiently deliver the product last week. The timeline was executed in a timely manner, and now it’s time for reflection. Each product we create improves with each iteration if we take the time to identify any potential improvements. 
	We developed this app in stages. Each class was a whole project itself. We then combined the whole project to make sure it ran smoothly with no errors. The testing process was executed throughout the timeline to ensure we didn’t waste any precious time by missing errors. The agile method was followed so that we made sure we didn’t have to start the project all over again at any point. The software requirements laid out by our client (after discussions with our team to interpret their needs) at the beginning. We followed these requirements thoroughly and ensured that at every step of the process, we didn’t overlook any requiremnts. For example, each class had specific requirements for the amount of characters, description of strings, and what the program is allowed to do versus not do. We followed these as a team and broke all of the requirements down into small steps so that we didn’t miss any. We know our testing was effective because we continuously ran our Junit tests every time we made changes or completed a stage of the project. These stages are outlined out in the timeline PDF. We monitored the results of each run and determined whether changes were needed. We tested to make sure ID’s were null versus not null, proper character length, and proper variable names that matched throughout the whole app. We also tested more than this, but these are some examples. 
	Throughout testing, we had to make sure we were watching each other’s testing. What I mean is, we wanted to pass each other’s work around to keep bias out of the equation. To keep from having set ideas and trains of thought, we tested each other’s work. This way, we didn’t miss anything due to unnecessary reasons that inhibited the final project. Each developer worked hard on their own sections of the project and therefore, could defend parts of their work. This is expected, but they would be defending parts of their work that actually needed to be modified for the greater good of the whole application. We followed unit testing, testing portions of our code and allowing other team members to review our code throughout the whole project. In this way, as a team we can only improve. Unit testing with Junit allows us to break our project down into sections. We can then at the end add it all together and make sure the whole application works seamlessly. Other types of testing are process, integration, and function, for example. We follow an Agile method approach and really align with working on our project in units to make sure we thoroughly look at each section of our project. 
	As a team, we all understand the consequences of technical debt. We do not want to provide a product to a customer and then be told we have to rework the project. As a company, Grand Stream Systems aims to only deliver a product to a customer once – a one and done approach. We want to absolutely avoid technical debt – this is a reason we have stayed in business for so long. A customer can come to us and be assured that they receive an outstanding product that 100% follows all technical requirements that were laid out. They have signed off on what we worked on and know that that is what they are going to get. We take full responsibility for all projects we work on and know that if something does not work right, it has the potential to hurt people if it is that kind of project. We take this very seriously and instill caution in our team. Yes, we have a timeline, but we would rather be a couple weeks behind rather than deliver an underrated product. That is why we follow our testing process so closely. 


